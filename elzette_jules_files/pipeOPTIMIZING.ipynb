{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from copy import deepcopy\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('https://raw.githubusercontent.com/jjbl99/waterpump/master/xtrain_clean.csv')\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/jjbl99/waterpump/master/Pump_it_Up_Data_Mining_the_Water_Table_-_Training_set_labels.csv')\n",
    "x_test = pd.read_csv('https://raw.githubusercontent.com/jjbl99/waterpump/master/xtest_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num = y_train.replace(['functional','non functional', 'functional needs repair'], [0,1,2]) \n",
    "x_test_id = x_test['id']\n",
    "x_test = x_test.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Categorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-760bf5c0c969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxtrain_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mxtest_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-760bf5c0c969>\u001b[0m in \u001b[0;36mtrain_cats\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# I think that would be logistical one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_cats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# I think that would be logistical one\n",
    "def train_cats(df):\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): \n",
    "            df[n] = pd.factorize(df[n])[0]\n",
    "    return df\n",
    "xtrain_log = train_cats(x_train)\n",
    "xtest_log = train_cats(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean target encoding\n",
    "xcat_mean = deepcopy(x_train)\n",
    "xtest_mean = deepcopy(x_test)\n",
    "\n",
    "xcat_mean['target'] = deepcopy(y_num)['status_group']\n",
    "\n",
    "for n,c in x_train.items():\n",
    "        if is_string_dtype(c): \n",
    "            xcat_mean[n] = xcat_mean[n].map(xcat_mean.groupby(c)['target'].mean())\n",
    "            xtest_mean[n] = xtest_mean[n].map(xcat_mean.groupby(c)['target'].mean()) \n",
    "            #DID IT WORK FOR TEST? How to stock the value?\n",
    "\n",
    "xcat_mean = xcat_mean.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FS_PCA(x_train, y_num):\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x_train, y_num, test_size=0.2)\n",
    "    ytrain.drop('id', axis = 1, inplace = True)\n",
    "    yvalid.drop('id', axis = 1, inplace = True)\n",
    "    xtrain.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    xvalid.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    scaler = StandardScaler()\n",
    "    feature_list = xtrain.columns\n",
    "\n",
    "    xtrain_FS = xtrain\n",
    "    xvalid_FS = xvalid\n",
    "\n",
    "    xtrain_PCA = xtrain\n",
    "    xvalid_PCA = xvalid\n",
    "\n",
    "    xvalid_FS.drop(['date_recordedMonth','public_meeting','water_quality','quality_group','source_class','year_recorded','num_private'], axis = 1, inplace = True)\n",
    "    xtrain_FS.drop(['year_recorded','source_class','date_recordedMonth','public_meeting','water_quality','quality_group','num_private'], axis = 1, inplace = True)\n",
    "\n",
    "    pca = PCA(n_components= 15)\n",
    "    pca.fit(xtrain) \n",
    "    PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,svd_solver='auto', tol=0.0, whiten=False)\n",
    "    print(pca.explained_variance_ratio_)  \n",
    "\n",
    "    xvalid_PCA = pca.transform(xvalid)\n",
    "    xtrain_PCA = pca.transform(xtrain)\n",
    "    \n",
    "    return xtrain_FS, xvalid_FS, xtrain_PCA, xvalid_PCA, ytrain, yvalid\n",
    "\n",
    "xtFS_log, xvFS_log, xtPCA_log, xvPCA_log, yt_log, yv_log = FS_PCA(xtrain_log, y_num)\n",
    "\n",
    "xtFS_mean, xvFS_mean, xtPCA_mean, xvPCA_mean, yt_mean, yv_mean= FS_PCA(xcat_mean, y_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_RT (xtrain, xvalid, ytrain, yvalid):\n",
    "    etc = ExtraTreesClassifier(n_estimators=300, \n",
    "                                    min_samples_split=8,\n",
    "                                    max_features='sqrt',\n",
    "                                    max_depth=95)\n",
    "    etc.fit(xtrain, ytrain)\n",
    "    predetc = etc.predict(xvalid)\n",
    "    print('Training accuracy: ', accuracy_score(ytrain, etc.predict(xtrain)))\n",
    "    print('Validation accuracy: ', accuracy_score(yvalid, predetc))\n",
    "    return predetc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for FS with mean: \n",
      " \n",
      "Training accuracy:  0.933733164983\n",
      "Validation accuracy:  0.809175084175\n",
      "\n",
      "for FS with log: \n",
      "\n",
      "Training accuracy:  0.93367003367\n",
      "Validation accuracy:  0.804461279461\n",
      "\n",
      "for PCA with mean: \n",
      " \n",
      "Training accuracy:  0.947874579125\n",
      "Validation accuracy:  0.796212121212\n",
      "\n",
      "for PCA with log: \n",
      " \n",
      "Training accuracy:  0.949221380471\n",
      "Validation accuracy:  0.794865319865\n"
     ]
    }
   ],
   "source": [
    "#feature selection: \n",
    "print('\\nfor FS with mean: \\n ')\n",
    "ext_RT(xtFS_mean, xvFS_mean, yt_mean, yv_mean)\n",
    "\n",
    "print('\\nfor FS with log: \\n')\n",
    "ext_RT(xtFS_log, xvFS_log, yt_log, yv_log)\n",
    "\n",
    "print('\\nfor PCA with mean: \\n ')\n",
    "ext_RT(xtPCA_mean, xvPCA_mean, yt_mean, yv_mean)\n",
    "\n",
    "print('\\nfor PCA with log: \\n ')\n",
    "ext_RT(xtPCA_log, xvPCA_log, yt_log, yv_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XGB(xtrain, xvalid, ytrain, yvalid):\n",
    "    xgb = XGBClassifier(max_depth=9, n_estimators=300,objective='multi:softmax') \n",
    "    xgb.fit(xtrain,ytrain)\n",
    "    trainxgb = xgb.predict(xtrain)\n",
    "    predxgb = xgb.predict(xvalid)\n",
    "    print('Training accuracy: ', accuracy_score(ytrain, trainxgb))\n",
    "    print('Validation accuracy: ', accuracy_score(yvalid, predxgb))\n",
    "    return predxgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ytrain.drop('id', axis = 1, inplace = True)\n",
    "#yvalid.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for FS with mean: \n",
      " \n",
      "Training accuracy:  0.933038720539\n",
      "Validation accuracy:  0.803451178451\n",
      "\n",
      "for FS with log: \n",
      "\n",
      "Training accuracy:  0.936069023569\n",
      "Validation accuracy:  0.804461279461\n",
      "\n",
      "for PCA with mean: \n",
      " \n",
      "Training accuracy:  0.935101010101\n",
      "Validation accuracy:  0.788383838384\n",
      "\n",
      "for PCA with log: \n",
      " \n",
      "Training accuracy:  0.935206228956\n",
      "Validation accuracy:  0.785774410774\n"
     ]
    }
   ],
   "source": [
    "#feature selection: \n",
    "print('\\nfor FS with mean: \\n ')\n",
    "XGB(xtFS_mean, xvFS_mean, yt_mean, yv_mean)\n",
    "\n",
    "print('\\nfor FS with log: \\n')\n",
    "XGB(xtFS_log, xvFS_log, yt_log, yv_log)\n",
    "\n",
    "#PCA\n",
    "print('\\nfor PCA with mean: \\n ')\n",
    "XGB(xtPCA_mean, xvPCA_mean, yt_mean, yv_mean)\n",
    "\n",
    "print('\\nfor PCA with log: \\n ')\n",
    "XGB(xtPCA_log, xvPCA_log, yt_log, yv_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have xtest_mean, xtest_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14850, 59400]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-5eaa9bc5e57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtFS_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvFS_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtPCA_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvPCA_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFS_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxtFS_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvFS_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtPCA_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvPCA_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv_mean\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFS_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-0768028e9f8e>\u001b[0m in \u001b[0;36mFS_PCA\u001b[0;34m(x_train, y_num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mFS_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0myvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 173\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14850, 59400]"
     ]
    }
   ],
   "source": [
    "xtFS_log, xvFS_log, xtPCA_log, xvPCA_log, yt_log, yv_log = FS_PCA(xtest_log, y_num)\n",
    "\n",
    "xtFS_mean, xvFS_mean, xtPCA_mean, xvPCA_mean, yt_mean, yv_mean= FS_PCA(xtest_mean, y_num)\n",
    "\n",
    "xtrain_FS.drop(['year_recorded','source_class','date_recordedMonth','public_meeting','water_quality','quality_group','num_private'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = ext_RT(xtFS_mean, xvFS_mean, yt_mean, yv_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
